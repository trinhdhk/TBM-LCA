\newpage
\setcounter{table}{0}
\setcounter{figure}{0}
\setcounter{page}{1}
\setcounter{section}{0}
\renewcommand{\thetable}{C\arabic{table}}
\renewcommand{\thefigure}{C\arabic{figure}}
\renewcommand{\thepage}{C\roman{page}}

# Clinical supplementary document {.unnumbered}

# Latent class analysis

## Motivation

In clinical research, logistic regression is the standard method to create a scoring system linking diagnostic features to a particular disease risk. Its reliability depends highly validity of the diagnostic gold standard. However, in the case of TBM, the uncertainty in diagnosis limits this approach. Although, positive ZN-Smear, MGIT, and Xpert are well-accepted in confirming TBM, a negative result for all three cannot rule out TBM. To address this, we utilised LCM. In this model we examine all possible combinations of test results and identify patterns more likely to be associated with TBM. In the next section, we describe the basic structure of the model and its assumptions.

## Classic LCM design

We describe the simplest form of our LCM and its underlying assumptions. We have 3 confirmatory test ("manifest") variables and a binary disease status, all with values 0 and 1. The estimation algorithm of classical LCA starts by formulating the probability of each of the 8 patterns of manifest variables. Each probability is split up by disease status $D$:

$$
P(T = t_1t_2t_3) = P(D=0) \times P(T = t_1t_2t_3 | D=0) + P(D=1) \times P(T = t_1t_2t_3 | D=1)
$$ {#eq:clin-lca-fml2}

where $d$, $t_1$, $t_2$, and $t_3$ are either $0$ or $1$.

The classical LCM assumes that the results of the three tests are unrelated given disease status; they are independent in a probabilistic sense. Then the disease specific probability of each pattern is a product of the probabilities per test ($T_1$, $T_2$, and $T_3$). In our specific case, $(T_1, T_2, T_3)$ are (ZN-Smear, MGIT, and Xpert) and we have per disease status:

$$
\begin{aligned}
P(T = 000 | D = d) &= P(T_1=0 | D = d) * P(T_2=0 | D=d) * P(T_3=0 | D=d)\\
P(T = 001 | D = d) &= P(T_1=0 | D = d) * P(T_2=0 | D=d) * P(T_3=1 | D=d) \\
P(T = 010 | D = d) &= P(T_1=0 | D = d) * P(T_2=1 | D=d) * P(T_3=0 | D=d) \\
P(T = 011 | D = d) &= P(T_1=0 | D = d) * P(T_2=1 | D=d) * P(T_3=1 | D=d) \\
P(T = 100 | D = d) &= P(T_1=1 | D = d) * P(T_2=0 | D=d) * P(T_3=0 | D=d) \\
P(T = 101 | D = d) &= P(T_1=1 | D = d) * P(T_2=0 | D=d) * P(T_3=1 | D=d) \\
P(T = 110 | D = d) &= P(T_1=1 | D = d) * P(T_2=1 | D=d) * P(T_3=0 | D=d) \\
P(T = 111 | D = d) &= P(T_1=1 | D = d) * P(T_2=1 | D=d) * P(T_3=1 | D=d) \\
\end{aligned}
$$ {#eq:clin-lca-fml}

These equations show the probability of different combinations of test results (T) given a certain disease status (D). For example, the first one shows the probability of all three test results being negative (T=000) when the disease status is d.

As all the tests are either negative or positive, $Pr(T_1=0|D=d))=1-Pr(T_1=1|D=d))$, $Pr(T_2=0|D=d))=1-Pr(T_2=1|D=d))$, $Pr(T_3=0|D=d))=1-Pr(T_3=1|D=d))$. Let k = 1,2,3 represents the test 1,2 3, the estimates the test sensitivities $Pr(T_k=1|D=1)$, specificities $Pr(T_k=0|D=0)$ and the TBM risk $P(D = 1)$ as the values that fit the observed frequencies of the patterns.

## Extensions to the classical LCM

### Prevalence model

The $P(D = 1)$ as estimated from the classical LCA is the prevalence of TBM in the study population; it does not account for individual variations in TBM risk. To better represent this variation a prevalence model has been added, in which the diagnostic features are covariables in the logistic regression as we discussed in Supplementary section \@ref(motivation). We call this the *prevalence model* (Statistical Supplementary Section \@ref(mathematical-parametrisation)). Somewhat simplified, the process involves a series of steps:
  
1. Fit the classical LCM (indicator model) to the data
2. For each individual:
    a. Use 1. to look up the corresponding probability of TBM given the pattern of test results
    a. Randomly allocate that individual to the TBM or non-TBM group according to that probability
  
3. Fit the logistic regression to the dataset with all individuals assigned the TBM status from 2.
4. Repeat step 2 and 3 multiple times ($\approx$ 40000 times) to get more precise results
5. Combine all the results to quantify the Bayesian posteriors of the coefficients

The additional sophistication in the algorithm is that the output from the logistic regression in step 3. is used to update individual probabilities to have TBM that are used in step 2.b. 

### Latent bacillary burden

Classical LCM assumes that ZN-Smear, MGIT, and Xpert are independent within TBM status. This means that the mechanistic pathways ruling these tests are completely separated, which is unlikely to be true. Violating the assumption can bias the result. We followed a proposed method [@eq:clin-lca-fml] aand added an additional covariable to the indicator model to correct this. In case such a factor is not measured, a random effect is added. In our study, we assumed the existence of a variable that was not measured called the "mycobacillary burden" [@qu1996]. This variable might depend on other variables that are measured, which we called "modulating factors". The details are formulated in the Statistical supplementary document.

# Calculation of post-test relative TBM risk

The post-test relative TBM risk quantifies how much lower the risk of TBM given some or all tests have returned negative (Section \@ref(stats-analysis)). This quantification $r_P$ is an population average and is not a replacement for individual post-test risk estimates [@eq:post-test]. However, this can be useful, especially to justify for the benefit of any repetition of the lumbar puncture. The web app [@tbmrepo], however, can quantify this risk on the individual level. 

$$
\begin{aligned}
P(TBM | test) &= \frac{P(TBM) \times P(test|TBM)}{P(test)} \\
r_P = \frac{P(TBM | test)}{P(TBM)} &=  \frac{P(test|TBM)}{P(test)}
\end{aligned}
$$ {#eq:post-test}

> where $test$ is the set of available test results in each scenario (*a* to *e*). The calulation is directly derived from Bayes' rule where $P(TBM)$ is the prior probability of each individual, $P(test)$ is the conditional probability, and $P(TBM|test)$ is the posterior probability (the probaility of TBM after the test).

# Rationales for chosen methods to handle missing values

We handled missing data differently depending on the reason why the data was missing. ZN-Smear, MGIT, and Xpert were not done if there was a shortage of CSF samples and TBM was not suspected. We assumed these patients were all without TBM and negative for the TBM microbiological assays as these are assumed to have high specificity [@nhu2013; @heemskerk2018]. Since HIV tests were done for all patients with suspected infection and/or involvement in high-risk activities, we could safely assumed that in those who were untested, the prevalence of HIV was close to zero, as the population prevalence of HIV in Vietnam is 0.3% [@UNAIDS2020]. 

A summary of the suspected mechanisms of missingness and our methods to handle them is shown in Supplementary Table \@ref(tab:missing-handling). In case a predictor is missing at random (MAR) or completely at random (MCAR), we performed a model-based imputation within the main model as part of the MCMC procedure. Further details of the imputation models are discussed in the Statistical Supplementary Section \@ref(stat-impute). 

```{r missing-handling, tab.cap="Rationales for chosen methods to handle missing values", tab.id="missing-handling"}
na = \(x) sum(is.na(x))
data_dirty$csf_neutro <- data_dirty$NEUPER * data_dirty$csf_wbc / 100
data_dirty |>
  dplyr::filter(pop) %$%
  # dplyr::filter(!(wrong_name %in% TRUE) & !(csf_mgit_contaminated %in% TRUE)) %$%
  tibble::tribble(
     ~ 'Variable'           , ~ 'N\n missing'     ,  ~ 'Expected Reason of Missingness'                      , ~ 'Mechanism',        ~ 'Handling method' ,
    'ZN-Smear'              , na(csf_smear)       , 'TBM not suspected'                                      , 'MNAR'               , 'Set = 0'          , 
    'MGIT'                  , na(csf_mgit)        , 'TBM not suspected'                                      , 'MNAR'               , 'Set = 0'          , 
    'Xpert'                 , na(csf_xpert)       , 'TBM not suspected'                                      , 'MNAR'               , 'Set = 0'          , 
    'HIV Status'            , na(hiv_stat)        , 'HIV infection not suspected'                            , 'MNAR'               , 'Set = 0'       ,
    'TB-suggestive symptoms', na(clin_symptoms)   , 'Unmeasured / Unconscious'                               , 'MAR'                , 'Imputation[^**]
    
[^**]: A missing of the any compartment of TB-suggestive symtomps (Weight loss, Night sweat, and Coughing > 2 weeks) is likely a MAR given other observed compartments.
',
    'Focal neurological deficit', na(clin_motor_palsy), 'Unconscious'                                        , 'MAR/MCAR'           , 'Imputation[^***]

[^***]: A missing of the any compartment of Focal neurological deficit (Hemiplegia, Paraplegia, and Tetraplegia) is likely a MAR given other observed compartments.
',
    'Glasgow Coma Score'    , na(clin_gcs)        , 'Ventilated (GCSV) / Data input error'                   , 'MNAR/MCAR'                , 'Imputation[^*]
    
    
[^*]: GCS is represented by 4 variables: E, V, M, and ReducedConsciousness. The last variable is never missing, indicating if GCS < maximum GCS (15 for normal cases and 10 for ventilated cases). GCS is set to 15 if ReducedConsciousness = False and not considered as missing. Otherwise, a missing of all three compartments (E, M, and V) is likely a data input error - which is MCAR - and a missing GCSV alone is likely due to ventilation and may suggest MNAR. In the latter case, we assume that we can impute GCSV based on GCSM and GCSE without bias.',
    'Symptoms duration'     , na(clin_illness_day), 'Patient forgets / Unconscious'                          , 'MAR'                , 'Imputation'       ,
    'Blood Glucose'         , na(BLDGLU)          , 'Input error / Unmeasured (premature death)', 'MAR/MCAR'           , 'Imputation'       ,
    'CSF glucose'           , na(csf_glucose)     , 'Input error /U nmeasured (premature death)'              , 'MAR/MCAR'           , 'Imputation'       ,
    'CSF lymphocyte count'  , na(csf_lympho)      , 'Implicit zero / Input error / Unmeasured (premature death)', 'MNAR/MAR','Manually set if implicit zero/Imputation otherwise',
    'CSF WBC count'         , na(csf_wbc)  , 'Implicit zero / Input error / Unmeasured (premature death)'    , 'MNAR/MAR'  , 'Manually set if implicit zero/Imputation otherwise',
    'CSF protein'           , na(csf_protein)     , 'Input error / Unmeasured (premature death)'             , 'MAR/MCAR'           , 'Imputation'       ,
    'CSF lactate'           , na(csf_lactate)     , 'Unmeasured (premature death)'                           , 'MAR/MCAR'           , 'Imputation' ,    
    'Cryptococcal test'     , sum(!(CRYTO=='NOT DONE'&INDIAINK=='NOT DONE')%in%F) , 'Cryptococcal meningitis not suspected', 'MNAR' , 'Set = 0',
    'Gram stain'            , sum(is.na(GRAM) | GRAM=='NOT DONE') , 'Bacterial meningitis not suspected'     , 'MNAR'               , 'Set = 0',
    # 'Fever'                 , na(clin_fever)      , 'Input error/Reduced consciousness'                      , 'MCAR/MAR'           ,'Imputation',
    'Headache'              , na(clin_headache)   , 'Reduced consciousness'                                  , 'MAR'                , 'Imputation',
    'Neck stiffness'        , na(clin_neckstiff)  , 'Reduced consciousness'                                  , 'MAR'                , 'Imputation',
    'Psychosis'             , na(clin_psychosis)  , 'Reduced consciousness'                                  , 'MAR'                , 'Imputation'
  ) |>                
  flextable::flextable() |>
  ftExtra::colformat_md(5) |>
  # flextable::set_caption('Rationale and method of missing values handling') |>
  flextable::width(width = 1.25) |>
  # flextable::footnote(i = c(14,15),j = 1,inline=FALSE,
  #                     value=flextable::as_paragraph(rep('CSF Lymphocyte count was calculated by CSF white-cell count x Percentage of lymphocyte / 100; if very low, then either lymphocytes or neutrophils had values, the other were left missing')),
  #                     part = 'body') |>
  flextable::add_footer_row(values = 'MCAR: missing completely at random; MAR: missing at random; MNAR: missing not at random', colwidths = 5) |>
  flextable::merge_v(part='footer') |>
  flextable::theme_vanilla() |>
  flextable::bold(bold=FALSE, part='footer') |>
  flextable::italic(italic=TRUE, part='footer') |>
  flextable::align(j=2, align = 'center') |>
  flextable::align(j=2, align = 'center', part = 'header')
```

# Use of prior knowledge {#appendix-prior-choices}

Supplementary Table \@ref(tab:predictor-tab) displays our expected impact of diagnostic features to the individual risk of TBM. We assigned a moderate amount of prior information to the coefficients, with two exceptions. First, variables that are strongly believed to have positive/negative association with the risk were constrained to have positive/negative coefficients. The other exception was for CSF WBC count where we allowed for a quadratic relationship as suggested by prior consensus [@marais2010].

```{r predictor-tab, tab.id="predictor-tab", label='tab0', out.width="100%", tab.cap="Expected impact of demographic and clinical features on the individual TBM risk and CSF mycobacterial burden based on prior knowledge. Signs + and - in each cell indicate the expected direction of association, followed by the level of confidence - if unknown, a ? is marked, an empty cell means that we expect no association"}
tibble::tribble(
  ~ 'Predictor'                    , ~ 'TBM prevalence', ~ 'Bacillary Burden',
  'HIV infection'                  , '+, strong', '+, strong'         ,
  'Past TB contact'                , '+, weak'  , ''                  ,
  'TB-suggestive symptoms'         , '+, weak'  , ''                  ,
  'Focal neurological deficit'     , '+, weak'  , ''                  ,         
  'Cranial nerve palsy'            , '+, weak'  , ''                  ,
  'Symptom duration'               , '+, weak'  , ''                  ,
  'PTB/X-ray'                      , '+, weak'  , ''                  ,
  'MTB/X-ray'                      , '+, strong', ''                  ,
  'Glasgow Coma Score'             , '-, weak'  , ''                  ,
  'Cryptococcus Antigen/Indian Ink', '-, strong', ''                  ,
  'Positive Gram stain'            , '-, strong', ''                  ,
  'Blood glucose'                  , '-, weak'  , ''                  ,
  'CSF glucose'                    , '-, weak'  , '?, weak'           ,
  'CSF lymphocyte count'           , '+, weak'  , '-, weak'           ,
  'CSF WBC count'     , '+-[^*], weak
  
  [^*]: Risk of TBM peaks with intermediate CSF white cell count' , '+, weak'  ,
  'CSF protein'                    , '+, weak'  , '+, weak'           ,
  'CSF lactate'                    , '+, weak'  , '+, weak'           ,
  'CSF eosinophil count'           , '-, strong', ''                  ,
  'CSF RBC Count'                  , '?, weak'   , ''
) |>
  flextable::flextable() |>
  ftExtra::colformat_md(2, .footnote_options = ftExtra::footnote_options(ref='1')) |>
  flextable::width(j=1, width=2) |>
  flextable::width(j=2:3, width=1.2) |>
  flextable::theme_vanilla() |>
  flextable::bold(bold = FALSE, part = "footer") |>
  flextable::italic(italic = TRUE, part = "footer" )
```

For ZN-Smear, MGIT, and Xpert, we collected prior information from several previous studies [@nhu2013; @thwaites2004; @heemskerk2018]. A summary of these choices is shown in Supplementary Figure \@ref(fig:mv-priors)), on linear and logistic scale. We demonstrated how good they cover corresponding results derived from the previous studies. As suggested in the literature, we used highly informative priors for False Positive Rate ($FPR = 1-Specificity$). Given the discrepancies between the studies, we used weakly informative priors for True Positive Rate ($TPR = Sensitivity$). All are specified on the logit scale.

```{r mv-priors, fig.cap="ensity plots for prior distributions and their correspondence to prior knowledge of sensitvity and specifity of TBM confirmation tests, evaluated against then-made clinical diagnosis. Note that Thwaites 2004 was descriptive and only gave sensitivities. Specificities for ZN-Smear and Culture in Nhu 2013 were references. Hence no Confidence Intervals were given in all sensitivities reported by the former and the specificities for ZN-Smear and Culture reported by the latter.", warning=FALSE,  fig.align='center', out.width='90%', fig.id="mv-priors", fig.height=8, dpi=300 }
sen_tbl <-
  tibble::tibble(
    'Test' = rep(c('ZN-Smear', 'Culture', 'Xpert'), 3),
    'Study' = rep(c('Thwaites 2004', 'Nhu 2013', 'Heemskerk 2018'), each=3),
    'est' = c(58/100, 64/100, NA, 78.64/100, 66.54/100, 59.34/100, 34.54/100, 31.84/100, 25.14/100),
    'lower.ci' = c(NA, NA, NA, 71.94/100, 59.14/100, 51.84/100, 29.94/100, 27.34/100, 21.04/100),
    'upper.ci' = c(NA, NA, NA, 84.34/100, 73.34/100, 66.54/100, 39.44/100, 36.74/100, 29.74/100)
  )

spc_tbl <-
  tibble::tibble(
    'Test' = rep(c('ZN-Smear', 'Culture', 'Xpert'), 3),
    # Test_id = rep(c(3,1,2), 2),
    'Study' = rep(c('Thwaites 2004','Nhu 2013', 'Heemskerk 2018'), each=3),
    'est' = c(NA, NA, NA, 0, 0, 0.05/100, 0, 0, 0),
    'upper.ci' = c(NA, NA, NA, NA, NA, (100-97.2)/100, (100-97.1)/100, (100-96.9)/100, (100-96.1)/100),
    'lower.ci' = c(NA, NA, NA, NA, NA, 0, 0, 0, 0)
  )

spc_rng = rbind(
  data.frame(
    Test = 'ZN-Smear',
    Test_id = 1,
    logit = rlogis(1000000,qlogis(.001),1),
    linear = rlogis(1000000,qlogis(.001),1) |> plogis()
  ),
  data.frame(
    Test = 'Culture',
    Test_id = 2,
    logit = rlogis(1000000,qlogis(.001),1),
    linear = rlogis(1000000,qlogis(.001),1) |> plogis()
  ),
  data.frame(
    Test = 'Xpert',
    Test_id = 3,
    logit = rlogis(1000000,qlogis(.005),.7),
    linear = rlogis(1000000,qlogis(.005),.7) |> plogis()
  )
) |>
  filter(linear<.07)

sen_rng = rbind(
  data.frame(
    Test = 'ZN-Smear',
    Test_id = 1,
    logit = rlogis(500000, 0,.35),
    linear = rlogis(500000, 0,.35) |> plogis()
  ),
  data.frame(
    Test = 'Culture',
    Test_id = 2,
     logit = rlogis(500000, 0,.35),
    linear = rlogis(500000, 0,.35) |> plogis()
  ),
  data.frame(
    Test = 'Xpert',
    Test_id = 3,
    logit = rlogis(500000, 0,.35),
    linear = rlogis(500000, 0,.35) |> plogis()
  )
) 

spc_linear_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=linear), data=spc_rng) +
  geom_point(aes(y= est, color = Study, x = -.2), data=spc_tbl, position=position_dodge(.2), shape=18, size=3) + 
  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci, color = Study, x = -.2), data=spc_tbl, position=position_dodge(.2)) +
  coord_flip(ylim=c(0,.07))+
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  scale_color_discrete(drop=FALSE)+
  theme_minimal() +
  theme(#text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

spc_logit_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=logit), data=spc_rng) +
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  coord_flip() +
  theme_minimal() +
  theme(#text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

sen_linear_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=linear), data=sen_rng) +
  geom_point(aes(y= est, color = Study, x = -.2), data=sen_tbl, position=position_dodge(.2), shape=18, size=3) + 
  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci, color = Study, x = -.2), data=sen_tbl, position=position_dodge(.2)) +
  coord_flip()+
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  theme_minimal() +
  theme(#text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

sen_logit_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=logit), data=sen_rng) +
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  coord_flip() +
  theme_minimal() +
  theme(#text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
  

plt <- (spc_linear_plt + ggtitle('FPR (1-Specificity)') + theme(legend.position = "none") | spc_logit_plt) /
  (sen_linear_plt + ggtitle('TPR (Sensitivity)') + theme(legend.position = "bottom") | sen_logit_plt) 

for (i in 1:2) plt[[i]] <- plt[[i]] + plot_layout(tag_level = 'new')
color_me <- list("#000000", "#E69F00", "#56B4E9", c("#000000", "#E69F00", "#56B4E9", "#009E73"))
withr::with_options(
  list(ggplot2.discrete.colour = color_me),

  plt + plot_annotation(tag_levels = list(c('',''), 'A'), caption='A: Linear scale, B: Logistic Scale \n Black dots, thick lines and thin lines are median, IQR, and 95% inter-percentile range') + plot_layout(guides = 'collect') & theme(plot.tag = element_text('serif', size = 9), legend.position = "bottom") 
)
```

The details of the choice of priors are outlined in the Statistical Supplementary Section \@ref(appendix-stat-prior-choices).

# Model estimates in details

This Supplementary Section outlines all the estimates of the selected model, if not mentioned in the main text.

## Prevalence model

The medians and 95% CrIs of all estimates are reported in Supplementary Table \@ref(tab:prev-model-est), the estimated TBM risk for each individual in the analysed sample is reported in Supplementary Figure \@ref(fig:individual-risk).

```{r prev-model-est, tab.id = 'prev-model-est', tab.cap = 'Medians and 95\\% credible intervals of TBM odds ratios, with respects to diagnostic features', warnings=FALSE, message=FALSE}
recover_scale <- \(x) sign(x) * x^2
coefs <- readRDS(file.path(data_dir, '../export/a_orig.RDS')) |> as.data.frame()
labs <- data.frame(Parameter = plot_m$a_plot$data$parameter, Label = rev(plot_m$a_plot$scales$get_scales('y')$labels)) |>
  mutate(Parameter = stringr::str_replace_all(plot_m$a_plot$data$parameter|>as.character(), '(^t\\()|(\\)$)', '')) |> distinct() %>% mutate(order = 1:nrow(.))
coefs_summary <- coefs[] |>
  tidyr::pivot_longer(
    cols=everything(),
    names_to = 'Parameter',
    values_to = 'Value'
  ) |>
  with_groups(Parameter, 
  ~ summarise(.x,
    m = median(Value), ll = quantile(Value, .025), hh = quantile(Value, .975)
  )) |>
  right_join(labs) |> arrange(by=order)
prev_model_est <- 
  coefs_summary |>
  mutate(
    Label = 
      Label |>
      stringr::str_replace_all(pattern = '<\\/?sup>', '^') |>
      stringr::str_replace_all(pattern = '<\\/?sub>', '~'),
    ll = round(exp((ll)), 6), 
    hh = round(exp((hh)), 6), 
    m = round(exp((m)), 6)) |>
  select(Parameter=Label, Median = m,  `95% CrI\nlower limit` = ll, `95% CrI\nupper limit` = hh) |>
  mutate(across(-Parameter, 
                ~ case_when(
                  .x < 0.01 ~ formatC(.x, digits=0, format='e', drop0trailing = F),
                  .x < 1000 ~ formatC(.x, digits=2, format='f', drop0trailing = F),
                  TRUE ~ formatC(.x, digits=3, width=4, format='g', flag='#', drop0trailing=T)
                )))
                

prev_model_est |>
  flextable::flextable() |>
  flextable::width(j = 1, width = 2) |>
  flextable::theme_vanilla() |>
  ftExtra::colformat_md(j=1)

```

```{r individual-risk, ig.align='center', out.width='100%', fig.dim=c(8, 8), fig.cap = "Histogram of individual probability to have TBM the analysed sample, as estimated by the selected model. x axis is the TBM probability, The count on the y axis is the estimated number of individuals in each bin. Microbiologically confirmed cases are coloured in orange.", warning=FALSE, message=FALSE}

# library(ggbreak)
theta <- jsonlite::fromJSON(file.path(data_dir, '../export/m3_theta.json')) |> as.matrix()
mean_theta <- apply(theta, 2, median)
plt <- ggplot(mapping=aes(x=mean_theta, fill = data_19EI[, csf_smear+csf_xpert+csf_mgit>0])) + 
  geom_histogram() + ggsci::scale_fill_jco()
plt_data <- ggplot_build(plt)$data[[1]]
bin_theta <- apply(theta, 1, 
    \(x) cut(x, breaks = c(0, unique(plt_data$xmax))) |> table() |> c())
bin_theta_confirmed <- apply(theta[,data_19EI[,(csf_smear + csf_mgit + csf_xpert > 0)]], 1, 
    \(x) cut(x, breaks = c(0, unique(plt_data$xmax))) |> table() |> c())
plt_data$count = c(
  apply(bin_theta-bin_theta_confirmed, 1,median), apply(bin_theta_confirmed,1,median)
)

upper_ci <- \(x) quantile(x, .975)
lower_ci <- \(x) quantile(x, .025)
plt2 = ggplot() + 
  stat_identity(aes(x=x, y=count, fill=rep(c( "#C7C7C7", '#FC8D62'), each=length(x)/2)), data=plt_data, geom='bar')+
  scale_fill_identity()+
  # geom_errorbar(aes(x = unique(plt_data$x),
  #   ymin = apply(bin_theta,1,lower_ci),
  #   ymax = apply(bin_theta,1,upper_ci)),
  #   width = .01, inherit.aes = F) +
  theme_bw() + 
  labs(x='TBM probability', y='Count') + 
  ggbreak::scale_y_break(c(60, 180), scales=0.5)
plt2

```
## Bacillary burden model

```{r bd-model-est, tab.id = 'bd-model-est', tab.cap = 'Estimates and 95\\% credible intervals of standardised bacillary burden, with respects to modulating factors'}

bd_model_est <- 
  m3$b_plot$data |> 
  mutate(
    Parameter = 
      rev(m3$b_plot$scales$get_scales('y')$labels) |>
      stringr::str_replace_all(pattern = '<\\/?sup>', '^') |>
      stringr::str_replace_all(pattern = '<\\/?sub>', '~'),
    ll = round(ll, 2), hh = round(hh, 2), m = round(m, 2)) |>
  select(Parameter, Median = m, `Lower 95% CrI` = ll, `Higher 95% CrI` = hh)

bd_model_est |>
  flextable::flextable() |>
  ftExtra::colformat_md(j=1) |>
  flextable::width(j = 1, width = 2) |>
  flextable::theme_vanilla()
```

# Comparison with current approaches

```{r load_compared_data, message=FALSE, warning=FALSE, include=FALSE}
corr_test <- readRDS(file.path(data_dir, '../export/test_corr.RDS'))
```

## Comparing predicted TBM risk and the uniform case definition

This section compares the prediction of our selected model and the standard TBM uniform case definition [@marais2010] (Supplementary Figure \@ref(fig:defscore)). We excluded the results from the confirmatory tests in the score. Visually, there is a positive correlation between the two, with patients with lower score having lower mean TBM probability. However, without the definitive mycobacterial tests, the uniform case definition missed out some confirmed cases as they were classified into the unknown group (total score \textless{} 6).

An interesting phenomenon is that the correlation is not monotonous. Patients with score < 6 have the same risk at those who have a score 5-6 points higher (for instance, those scoring 4 had similar risk distribution as those scoring 9). We attempted to address this via a  "quick fix" by adding 5 to those whose score $\leq$ 6. This indeed improves he correlation and the fitted curve (Supplementary Figure \@ref(fig:defscore2)). In some cases where risk re-estimation is of interest, but relevant data on diagnosis features retrievable, this "fix" can provide an imperfect solution.

## Comparing the risk score and TBM risk based on the simplified prevalence model

The screening risk score (Table \@ref(tab:score-table)) is a direct derivation from the simplified prevalence model. This is a manual task that involves choosing a point estimate from within the 50% CrI for every coefficient, on the original scale of the corresponding covariable. The threshold (6) was calculated as the log-odd of the optimal cutpoint (28.2%) and after correction for the standardisation of diagnostic feature values. This section compares the risk score calculated from this table with the actual probability of TBM estimated by the simplified prevalence model (Supplementary Figure \@ref(fig:risk-score-comp)).


```{r}
#| label: risk-score-comp
#| message: FALSE 
#| warning: FALSE
#| out.width: '100%'
#| fig.cap: "Comparison of the TBM screening risk score and the TBM probability based on the simplified prevalence model" 
#| fig.asp: 1
#| fig.id: 'cultimefit'
#| fig.width: 9

posteriors <- readRDS(file.path(data_dir, '../export/posterior.RDS'))
inputs <- readRDS(file.path(data_dir, '../export/input_s.RDS'))
scales <- purrr::transpose(scale_Xc[c('id', 'gcs')])
Xd <- lapply(inputs, \(.x) .x$Xd_all) |> do.call(rbind, args=_)
# Rescale continuous values
Xc <- lapply(inputs, \(.x) (.x$Xc_all)) |> do.call(rbind, args=_)
Xc <- sapply(1:2, \(i) {
  Xc[,i] * scales$`scaled:scale`[[i]] + scales$`scaled:center`[[i]]
})
Xc[,2] <- 15-Xc[,2] # recover the GCS
Xc[,1] <- 2^(Xc[,1])

# Xd risk score
Xd_score_tbl <- risk_score_tbl |> 
    filter(
      Criterion %in% c(
        'HIV', 
        'TB-suggestive symptoms',
        'Local neurological deficit',
        'Cranial nerve palsy',
        'Past noticed TB contact',
        'Pulmonary TB/X-ray',
        'Miliary TB/X-ray',
        'Headache',
        'Fever',
        'Neck stiffness',
        'Psychosis'
        )
    ) %>% .$Score

Xd_score = Xd[,-3] %*% Xd_score_tbl #removet focal neurodeficit

#Xc risk score
id_score_tbl <- risk_score_tbl %>% filter(grepl('duration', Criterion)) %>% .$Score
id_score <- fcase(
  Xc[,1] == 1, id_score_tbl[1],
  Xc[,1] <= 4, id_score_tbl[2],
  Xc[,1] <= 7, id_score_tbl[3],
  Xc[,1] <= 14, id_score_tbl[4],
  Xc[,1] <= 21, id_score_tbl[5],
  default=id_score_tbl[6]
)

gcs_score_tbl <- risk_score_tbl %>% filter(grepl('GCS', Criterion)) %>% .$Score
gcs_score <- fcase(
  Xc[,2] <= 6, gcs_score_tbl[1],
  Xc[,2] <= 8, gcs_score_tbl[2],
  Xc[,2] <= 12, gcs_score_tbl[3],
  default = gcs_score_tbl[4]
)

total_score = Xd_score + id_score + gcs_score

ggplot(data=tibble(risk=posteriors$theta|>t()|>c()|>(\(x) x*100)(), score = factor(total_score), high_risk = total_score >= 14)) + geom_boxplot(aes(x=score, y=risk, fill=high_risk)) + labs(x = 'Total risk score', y = 'Simplified TBM risk', fill = latex2exp::TeX("Suspected TBM (score \\geq 14)")) + scale_fill_manual(values=c( "#C7C7C7", '#FC8D62')) + ggpubr::theme_pubclean() 
```

```{r}
#| label: roc-risk-score
#| fig.cap: 'ROC curve of the screening risk score against the final hospital diagnosis'
#| fig.dim: c(8, 8)
#| fig.id: 'roc-risk-score'
#| out.width: '100%'
#| message: FALSE
#| warning: FALSE

Xd_mean = lapply(inputs, \(.x) .x$Xd_all) |> abind::abind(along = 3) |> apply(1:2, mean)
Xc_mean = lapply(inputs, \(.x) .x$Xc_all) |> abind::abind(along = 3) |> apply(1:2, mean) 
Xc_mean <- sapply(1:2, \(i) {
  Xc_mean[,i] * scales$`scaled:scale`[[i]] + scales$`scaled:center`[[i]]
})
Xc_mean[,2] <- 15-Xc_mean[,2] # recover the GCS
Xc_mean[,1] <- 2^(Xc_mean[,1])

Xd_score_mean = Xd_mean[,-3] %*% Xd_score_tbl
id_score_mean <- fcase(
  Xc_mean[,1] == 0, id_score_tbl[1],
  Xc_mean[,1] <= 4, id_score_tbl[2],
  Xc_mean[,1] <= 7, id_score_tbl[3],
  Xc_mean[,1] <= 14, id_score_tbl[4],
  Xc_mean[,1] <= 21, id_score_tbl[5],
  default = id_score_tbl[6]
)
gcs_score_mean <- fcase(
  Xc_mean[,2] <= 6, gcs_score_tbl[1],
  Xc_mean[,2] <= 8, gcs_score_tbl[2],
  Xc_mean[,2] <= 12, gcs_score_tbl[3],
  default = gcs_score_tbl[4]
)
total_score_mean = Xd_score_mean + id_score_mean + gcs_score_mean
outcome = data_19EI[, (tbm_dx%in%T)|(csf_smear+csf_mgit+csf_xpert>0)]
rocs = pROC::roc(outcome~total_score_mean)
threshold.optim = with(rocs, which.max(sensitivities+specificities))

roc_score <- data.frame(m = total_score_mean, d = as.integer(outcome)) |> 
  ggplot() + plotROC::geom_roc(aes(d=d,m=m), cutoffs.at = c(14, 13, 12, 10, 8, 6), cutoff.labels = c(14,13,12,10,8,6), position = 'dodge') +
  geom_vline(aes(xintercept=1-rocs$specificities[threshold.optim]), color=gray(0.5)) + 
  geom_hline(aes(yintercept=rocs$sensitivities[threshold.optim]), color=gray(0.5))+
  annotate(geom='text', x=0.75, y=0.15, label = glue::glue('AUC = {(pROC::auc(data_19EI[, (tbm_dx%in%T)|(csf_smear+csf_mgit+csf_xpert>0)]~c(total_score_mean))*100)|>round(1)}%'))+
  plotROC::style_roc(xlab = '1-Specificity', ylab = 'Sensitivity')+
  scale_x_continuous(name = 'Specificity', breaks = c(0, .1, .2, .5, .8, .9, 1,1-rocs$specificities[threshold.optim]), labels = 1-c(0, .1, .2, .5, .8, .9, 1,1-rocs$specificities[threshold.optim] |> round(2)),  guide = guide_axis(n.dodge = 1, check.overlap = T),) + 
  scale_y_continuous(name = 'Sensitivity', breaks = c(0, .1, .2, .5, .8, .9, 1, rocs$sensitivities[threshold.optim]), labels =  c(0, .1, .2, .5, .8, .9, 1, rocs$sensitivities[threshold.optim] |> round(2)), guide = guide_axis(n.dodge = 1, check.overlap = T))

roc_score
```


## Comparing model-based bacillary burden and current measurement

This section compares our estimated standardised mycobacillary burden (SMB) with two tools to quantify mycobacterial load. These tools are the semi-quantification level by GeneXpert (based on CT value) and time to positivity (TTP) when performing culturing. The general downside of these quantification methods is that they require the corresponding tests to be positive. We assume negative patients to have low bacterial load.

We can see a positive correlation between our SMB and the Xpert level (Supplementary Figure \@ref(fig:xpert-lv)). The correlation were not obvious between SMB and TTP in the overall population. This might be due to small sample size. However, similar to a previous study [@najjingo2019], in the HIV-naive sub-population, we can see a negative correlation between TTP and SMB; that was however not obvious in the HIV-infected group (Supplementary Figure \@ref(fig:cultime)). The association was again supported by the linear regression between TTP and SMB, correction for HIV status and the interaction between TTP and HIV. The negative association was nullified by in HIV-positive sub-population (Supplementary Table \@ref(tab:cultimefit)). This contradicted the past study [@najjingo2019] and possibly due to the low number of TBM-HIV co-infection that had a positive MGIT culturing.

```{r cultimefit, message=FALSE, warning=FALSE, out.width='100%', tab.cap = "Comparison of our predicted SMB and TTP", tab.id = 'cultimefit'}

labelled::var_label(corr_test$cultimefit$model) <- list(burden="SMB", hiv="HIV", log_culture_time="log(TTP)")
# corr_test$cultimefit$model$hiv <- factor(corr_test$cultimefit$model$hiv, levels=c(F,T), labels=c("-", "+"))
tbl <- gtsummary::tbl_regression(corr_test$cultimefit, show_single_row=c('hiv', 'hiv:log_culture_time')) |>
  # gtsummary::as_hux_table() 
# tbl[-1,1] <- c("HIV", "log(TTP)", "HIV * log(TTP)", "CI = Confidence Interval")
# huxtable::as_flextable(tbl) |>
  gtsummary::as_flex_table() |>
  flextable::width(j = 1, width = 2) |>
  flextable::theme_vanilla()
tbl
```

\clearpage
\pagebreak
\newpage
\blandscape

```{r defscore, fig.align='center', out.width='100%', fig.dim=c(10, 8), fig.cap = "Comparison of our predicted TBM probability and the calculated scores and classes by the uniform definition", warning=FALSE, message=FALSE}
# library(ggside)
corr_test$defscore |> plot()
```

```{r defscore2, fig.align='center', out.width='100%', fig.dim=c(10, 8), fig.cap = "Comparison of our predicted TBM probability and the calculated scores and classes by the uniform definition, after correction", warning=FALSE, message=FALSE}
corr_test$defscore2 |> plot()
```

```{r xpert-lv, message=FALSE, warning=FALSE, fig.align='center', fig.cap='Comparison of our predicted SMB and Xpert semi-quantification level', fig.dim=c(12, 8), message=FALSE, warning=FALSE, out.width='100%'}
corr_test$xpertlv |> plot()
```

```{r cultime, message=FALSE, warning=FALSE,  fig.dim=c(12, 8), fig.align='center', out.width='100%', fig.cap = "Comparison of our predicted SMB and TTP", fig.asp=2}
# (plot(corr_test$cultime[[1]]) + ggtitle('HIV positive') + ylab('Time to Culture positive (hours)')) + (corr_test$cultime[[2]] + ggtitle('HIV negative') + theme(axis.title.y= element_blank()))
# corr_test$cultime$overall |> plot()
wrap_elements(corr_test$cultime$pos) + wrap_elements(corr_test$cultime$neg)
```

\elandscape
\clearpage