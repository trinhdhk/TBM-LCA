---
title: 'In search of a novel scoring system for Tuberculous Meningitis Diagnosis: a Bayesian Latent Class Analysis Approach'
author:
  - Trinh Dong Huu Khanh:
      email: trinhdhk@oucru.org
      institute: [oucru, kcl]
      correspondence: true
  - Joseph Donovan:
      institute: [oucru, lshtm]
  - Guy Thwaites:
      institute: [oucru, oxford]
  - Ronald Geskus:
      institute: [oucru, oxford]
institute:
  - oucru: Oxford University Clinical Research Unit, Centre for Tropical Medicine, Ho Chi Minh City, Vietnam 
  - kcl: King's College London, London, United Kingdom
  - lshtm: London School of Hygiene and Tropical Medicine, London, United Kingdom
  - oxford: Centre for Tropical Medicine and Global Health, Nuffield Department of Medicine, University of Oxford, United Kingdom 
output: 
  officedown::rdocx_document:
    fig_caption: yes
    reference_docx: includes/styles.docx
    pandoc_args:
      - '--lua-filter=includes/scholarly-metadata.lua'
      - '--lua-filter=includes/author-info-blocks.lua'
    toc: no
  bookdown::pdf_document2:
    toc: no
    pandoc_args:
      - '--lua-filter=includes/scholarly-metadata.lua'
      - '--lua-filter=includes/author-info-blocks.lua'
    latex_engine: xelatex
    keep_tex: yes
    highlight: pygments
    includes:
      in_header: includes/header.tex
bibliography: includes/references.bib
csl: includes/the-lancet-infectious-diseases.csl
---

```{r setup, include=FALSE}
options(tinytex.engine_args = '-shell-escape')
knitr::opts_chunk$set(echo = FALSE, dpi=300) #, dev = 'png'
flextable::set_flextable_defaults(fonts_ignore=TRUE, font.size=9, table.layout='fixed')
```

```{r library, include=FALSE}
library(gtsummary)
library(dplyr)
library(magrittr, include.only = '%$%')
library(ggplot2)
library(patchwork)
library(officedown)

# All the misc functions go here.
my_fn <- new.env()

## Add labels accross a tbl
my_fn$add_labels <- \(.data, ...){
  cols <- list(...)
  for (i in seq_along(cols))
    attr(.data[[names(cols)[i]]], 'label') <- cols[[i]]
  .data
}

## Register a knit engine for stan code highlight
my_fn$stan_knitr_engine <- \(options){
  out <- c('\\begin{Shaded}','\\begin{minted}{stan}', options$code, '\\end{minted}','\\end{Shaded}')
  options$echo <- FALSE
  options$results <- "asis"
  knitr::engine_output(options, options$code, out)
}
knitr::knit_engines$set(stan_code = my_fn$stan_knitr_engine)

## Gist to number equations
## https://gist.github.com/mcanouil/eb75057432ff77846f4273d8808e615a
my_fn$is_docx_output <- function (fmt = knitr:::pandoc_to()) {
  if (length(fmt) == 0) {
    return(FALSE)
  } else {
    return(fmt == "docx")
  }
}

my_fn$numberEq.docx <- function (eq, lab, envir = docx.eqcounter) {
  assign(x = "counter", value = get(x = "counter", envir = envir)+1, envir = envir)
  assign(x = gsub("eq:", "", lab), value = get(x = "counter", envir = envir), envir = envir)
  lab <- get("counter", envir = envir)
  return(c('$$', eq, '\\;\\;\\;\\;(', lab, ')', '$$'))
}
my_fn$labEq.docx <- function (lab, envir = docx.eqcounter) {
  return(paste0('(', get(x = gsub("eq:", "", lab), envir = envir), ')'))
}

docx.eqcounter <- new.env()
docx.eqcounter$counter <- 0
  
# Register a knit engine for formula
my_fn$aligned_formula_knit <- \(options){
  out <- my_fn$numberEq.docx(options$code, lab = options$fml.lab)
  options$echo <- FALSE
  options$results <- "asis"
  knitr::engine_output(options, options$code, out)
}
knitr::knit_engines$set(aligned_formula = my_fn$aligned_formula_knit)


# Global theming for ggplots
my_fn$plot_theme <-
  theme(text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

```

```{r data, include=FALSE}
data_dir <- '../../data/cleaned/'
load(file.path(data_dir, 'data_input.Rdata'))
data_dirty <- readRDS(file.path(data_dir, 'data_dirty.RDS'))
load(file.path(data_dir, '..', 'export', 'm3_summary.Rdata'))
load(file.path(data_dir, '..', 'export', 'm3_plot.Rdata'))
```

# Introduction

*Tuberculous meningitis (TBM)* is the most severe form of tuberculosis. Diagnosing TBM is notoriously challenging, with microbiological confirmation requiring identification of *Mycobacterium tuberculosis* in paucibacillary cerebrospinal fluid (CSF). In addition to widely used confirmatory methods of CSF testing for *M. tuberculosis* such as Ziehl-Neelsen (ZN) staining, GeneXpert MTB/RIF (Xpert), and Mycobacterial culture, additional information may increase the likelihood of a diagnosis of TBM. Such characteristics are illustrated in the uniform case definition for TBM[@marais2010] where, in the absence of positive microbiological tests, an increased certainty of TBM is assigned in the presence of particular clinical, CSF, and imaging findings, or with evidence of non-neurological *M. tuberculosis*.

In the absence of a gold standard for TBM diagnosis, the uniform case definition has been widely adopted, particularly for the evaluation of new index diagnostic tests. However, the uniform case definition was developed as a standardised approach to reporting TBM research, rather than a gold standard for TBM diagnosis. When categorising cases of suspected TBM, the uniform case definition allocates cases to one of four levels; *Definite*, *Probable*, *Possible*, and *Not TBM*, with both *Probable* and *Possible* each encompassing a numerical score range where higher scores increase the probability of a diagnosis of TBM. All *Probable* cases do not therefore have the same probability of having TBM. *Definite TBM* incorporates microbiological tests, which, in the case of mycobacterial culture, may not return a positive result for several weeks. The best combination of these characteristics to diagnose that represents TBM, whilst including no cases of *non-TBM*, is not known and probably lies beyond the use of 4 levels. True TBM cases are likely represented by all *Definite* cases, most *Probable* cases, and some *Possible* cases. Furthermore, some amongst these characteristics are not always available, particularly in resource-limited settings, consequently lead to arbitrary assumptions and reduce overall capability.  <!---On the other hands, due to not being developed upon discussions consensuses where a mere change does need more time and efforts, several statistical models can be re-fitted basing on one same dataset with different covariables, hence have more flexibility and adaptability in different scenarios. *(in case this is ambiguous: this closely links to one of our objectives where we build a simplified score table that uses only clinical and demographic data, for resources-limited settings and quick screening)*-->

An alternative is to combine characteristics in a statistical diagnostic model. In the absence of a gold standard, classical regression models do not suffice. *Latent Class Analysis (LCA)* is a technique which has been used in settings where a gold standard does not exist. This model assumes that the population can be split into different groups, and quantifies the probability to belong to each group based on individual characteristics. LCA is common in social science and psychology to detect different hidden traits[@Weller2020]. Recently, it has been adopted in several diagnostic studies, especially in Tuberculosis[@stout2018; @adams2019; @schumacher2016; @lahuerta-marin2018]. <!--The classical LCA usually requires indicators to follow different biological pathways, which hinders it applicability. The introduction of random effects and Bayesian approach has brought more flexibility to the model [@qu1996; @toft2005; @menten2008].-->

```{r classic-lca, fig.cap = "Design of classic Latent Class Analysis with two unobserved classes 1 and 2 and three iid. binary manifest variables (test 1, test 2, and test 3). Distributions of manifest variables in both classes are generated for demonstration only", out.width='90%', fig.id = "classic-lca", dpi=300, fig.cap.style = "Image Caption", fig.align='center', include=FALSE}
# knitr::include_graphics("includes/graph1.jpg")
# knitr::include_graphics('includes/classicLCA.svg')
fig_svg <- cowplot::ggdraw() + 
  cowplot::draw_image(magick::image_read_svg("includes/classicLCA.svg", width=212*5, height=159*5))
plot(fig_svg)
```

In this analysis, we implemented a latent class model to *(1)* re-evaluate the performance, namely sensitivities and specificities, of current TBM confirmatory methods - ZN Smear, Xpert, and mycobacterial culture - against actual TBM status, taking into account the imperfection in current diagnosis; *(2)* provide an alternative to the the diagnostic scoring system that estimates the probability of having TBM based on individual characteristics and compare both approaches.

As secondary objectives, our analysis also aim to build a simplified scoring system which only needs clinical and demographic information but has the capacity to approximate the full system's output - so that TBM risk can be calculated at admission. We also estimate a latent representation of individual bacillary burden given that they get TBM which may impact the tests results.

# Methods

## Participants

We used data from an observational study of brain infection conducted at the Hospital for Tropical Diseases (HTD), Ho Chi Minh City, Vietnam, a large centre providing secondary and tertiary treatment for a wide range of tropical infections[@thwaites2002]. This study received ethical approvals from HTD and the Oxford Tropical Research Ethics Committee[@donovan2020]. Participants were enrolled between 29th August 2017 and 22nd January 2021. Inclusion criteria included a minimum age of 16 years, having suspected brain infection, admitted to a neuro-infection ward, and undergoing lumbar puncture at baseline as a routine diagnostic procedure. Patients were ineligible for enrolment if performing a lumbar puncture was contraindicated, or if informed consent to join the study was not given (by the patient, or by a relative if the patient lacked capacity to consent). Specifically for this analysis, we also excluded patients with contaminated mycobacterial culturing results and with no subsequent culture in the first week since admission, concepts of which were later discussed in \@ref(data-collection-and-testing procedures).

## Data collection and testing procedures

For all participants, demographic data and medical history were recorded. HIV testing was performed on a case-by-case basis by the treating clinician. Patients admitted with a condition suggestive of immune deficiency or had been involved in high risk activities were tested for HIV. Patients with either a known HIV positive status, or a positive HIV test result, were considered HIV positive. Patients underwent clinical examination and laboratorial investigations according to main study protocol, including: blood test, sputum, and lumbar puncture, unless contra-indicated. Cerebro-spinal fluid (CSF) was obtained by lumbar puncture, with CSF white blood cells and cellular differential, CSF protein, CSF glucose (with paired blood glucose), and CSF lactate routinely measured. Optimally 6mls CSF was used for mycobacterial testing unless less CSF was available (in which case mycobacterial testing was still performed). Confirmatory tests for TBM performed on CSF and used for this analysis were Ziehl--Neelsen staining and smear (ZN Smear), mycobacterial culture using Mycobacteria Growth Indicator Tube (MGIT), and Xpert or Xpert MTB/RIF Ultra (XpertUltra). Since Xpert and XpertUltra were found diagnostically comparable in a subset of these data[@donovan2020], Xpert and XpertUltra were considered the same in this analysis and, are both denoted as Xpert. Confirmatory mycobacterial testing was performed if TBM was suspected by the treating clinician.

Methods of CSF processing have been described elsewhere[@nhu2013, @donovan2020]. Briefly: CSF samples were centrifuged at 3000g for 15 minutes, and most of the CSF supernatant was removed. The CSF deposit was resuspended in 500µL of remaining supernatant, with this resuspended pellet then used for ZN smear (100µL), MGIT (200µL), and either Xpert or XpertUltra (200 µL).

All patients received appropriate anti-TB chemotherapy regimens according to national and local treatment guidelines, depending on the diagnosis, without any interference from the study. At the time of discharge or death, all patients received a final diagnosis. If at least one of ZN Smear, Xpert, Xpert Ultra, or MGIT was positive at any time during the follow-up, the patient was considered confirmed TBM; otherwise, if TBM was clinically suspected and treated, with confirmatory microbiological tests negative, the patient would be considered suspected TBM. If the patient recovered without anti-TB chemotherapy they was reassigned to another diagnosis (i.e. not TBM).

In case of repeated CSF sampling (performed based on clinical need), only the first sample with at least 3mls of CSF collected not later than the first week since admission were used. Results of haematological and biochemical parameters, and of ZN Smear, Xpert, Xpert Ultra, and MGIT, were taken from the same CSF sample (in addition to the paired blood glucose).

## Statistical analysis

### Latent class regression model

We conducted a Bayesian Latent Class Model in which the three aforementioned TBM confirmatory tests (ZN Smear, MGIT, and Xpert) were used as manifest variables and the target latent class is the actual disease status (TBM or not TBM). All three tests are detection tool via direct visualisation under microscope (ZN Smear), via their DNA (Xpert), or via grown culture (MGIT). Predictors for the latent class were chosen according to background knowledge of potential risk factors [@marais2010] and are summarised in table \@ref(tab:predictor-tab). We added three parameters: (1) CSF oeosinophil count - a strong bio-marker for oeosinophilic meningitis, a condition usually caused by parasitic helminths; (2) Cryptococcus Antigen/Indian Ink - a confirmatory test for parasitic infection; and (3) CSF erythrocyte count - an independent marker for traumatic lumbar puncture, in which case we also made a correction to white cell counts and biochemical features[@greenberg2008; @nigrovic2011; @mehl1986]. Details of the model design are summarised in the supplementary document.

```{r predictor-tab, out.width="100%",  tab.cap="Contribution of different features to TBM prevalence and patients' mycobacillary burden for each model mentioned in table \\@ref(tab:model-archs), based on background knowledge. Cell values are the expected direction of association and level of confidence; empty cells mean no association assumed", tab.id = "predictor-tab", label='tab0'}
tibble::tribble(
  ~ 'Predictor'                    , ~ 'TBM prevalence', ~ 'Bacillary Burden',
  'Age'                            , '+, weak'  , ''                  ,
  'HIV infection'                  , '+, strong', '+, weak'    ,
  'Past TB contact'                , '+, weak'  , ''                  ,
  'TB-suggested symptoms'          , '+, weak'  , ''                  ,
  'Local motor deficit'            , '+, weak'  , ''                  ,         
  'Cranial nerve palsy'            , '+, weak'  , ''                  ,
  'Days from onset'                , '+, weak'  , ''                  ,
  'PTB/X-Ray'                      , '+, weak'  , ''                  ,
  'MTB/X-Ray'                      , '+, strong', ''                  ,
  'Glasgow Coma Score'             , '-, weak'  , ''                  ,
  'Cryptococcus Antigen/Indian Ink', '-, weak'  , ''                  ,
  'Blood Glucose'                  , '-, weak'  , ''                  ,
  'CSF Glucose'                    , '-, weak'  , '?, weak'     ,
  'CSF Lymphocyte Count'           , '+, weak'  , '-, weak'    ,
  'CSF Total While cell Count'     , '+-^[Risk of TBM peaks with intermediate CSF white cell count], weak' , '+, weak'    ,
  'CSF Protein'                    , '+, weak'  , '+, weak'    ,
  'CSF Lactate'                    , '+, weak'  , '+, weak'    ,
  'CSF Oeosinophil Count'          , '-, strong', ''                  ,
  'CSF RBC Count'                  , '?, weak'   , ''                 
) |>
  flextable::flextable() |>
  ftExtra::colformat_md(2) |>
  # flextable::footnote(i=16, j=2, 
    # value=flextable::as_paragraph('')) |>
  flextable::width(j=1, width=2) |>
  flextable::width(j=2:3, width=1.2) |>
  flextable::theme_zebra() |>
  flextable::bold(bold = FALSE, part = "footer") |>
  flextable::italic(italic = TRUE, part = "footer" )
```

```{aligned_formula, fml.lab='eq:fml-gcs', results='asis'}
\begin{aligned}
RGCS &= 15 - GCS \\
RGCS_{Eyes} &= 4 - GCS_{Eyes} \\
RGCS_{Verbal} &= 5 - GCS_{Verbal} \\
RGCS_{Motor} &= 6 - GCS_{Motor}
\end{aligned}
```

As most continuous variables were right-skewed, they were first transformed to logarithmic scale, after which they were centred and divided by corresponding standard deviations. Glasgow Coma Score (GCS) and Glasgow Coma Scale components (Voice - GCSV, Eyes - GCSE, and Muscle - GCSM) were translated to *Reversed GCS* as demonstrated in formula `r my_fn$labEq.docx('fml-gcs')`, so that a GCS of 15 is equal to a RGCS of 0 and a GCS of 3 is equal to RGCS of 12. Binary variables were dummy-coded into 0 for "Negative"/"No" and 1 for "Positive"/"Yes".

```{r gcs-tab, out.width='100%', tab.id='gcs-tab', tab.cap='Conversion table from clasic Glasgow Coma Score (GCS) to Reversed GCS (RGCS)', include=FALSE}

tibble::tribble(
  ~ Feature,                     ~ Response, ~ GCS, ~ RGCS,
  'Eye response',        'Open sponatenously', 4, 0,
  'Eye response',     'Open to voice command', 3, 1,
  'Eye response',              'Open to pain', 2, 2,
  'Eye response',               'No eye open', 1, 3,
  'Verbal response',             'Orientated', 5, 0,
  'Verbal response',               'Confused', 4, 1,
  'Verbal response',     'Inappopriate words', 3, 2,
  'Verbal response','Incomprehensible sounds', 2, 3,
  'Verbal response',     'No verbal response', 1, 4,
  'Motor response',            'Obey command', 6, 0,
  'Motor response',         'Localising pain', 5, 1,
  'Motor response',    'Withdrawal from pain', 4, 2,
  'Motor response',                 'Flexing', 3, 3,
  'Motor response',               'Extending', 2, 4,
  'Motor response',       'No motor response', 1, 5
) |>
  flextable::flextable() |>
  flextable::merge_v(j = 1) |>  
  flextable::width(j=1, width=2) |>
  flextable::width(j=2, width=2)
```

Compared to the uniform case definition, we also made a change to *Past TB contact*. We hypothesised that by interpreting the original question "contact with TB patients within the past year" into "*noticeable* contact with TB patients within the past year", we would be able to judge all "Unknown" answer as a "No". No brain imaging was taken in our data.

```{r model-archs, tab.cap="Model architectures and extensions", tab.id="model-archs"}
model_archs <-
  data.frame(
    Model=1:5,
    Def=c(
      'No bacillary burden; everyone in the same class has equal risk of tested positive',
      'Added individual bacillary burden; impacts of bacillary burden on test results are the same',
      'Impacts of bacillary burden are different for different tests',
      'Added technical fluctuation as a second random effect; fixed effects only contributes to bacillary burden',
      'Added fixed effects for technical fluctuation'
    )
  ) 

model_archs |> 
  flextable::flextable() |>
  flextable::set_header_labels(
    Model='Model', 
    Def='Base definition (Only added effects compared to lower number are mentioned)'
  ) |>
  flextable::width(j=1, width=.5)|>
  flextable::width(j=2, width=5) |>
  flextable::theme_zebra()
```

The basic design of our model is shown in figure \@ref(fig:skeleton-model). Our models consist of one logistic regression estimating the prevalence of TBM in the population (prevalence model) and linear regression estimating the latent bacilliary burden among TBM positive patients (bacillary burden model); this bacillary burden contributes to We considered a range of models increasingly flexible and less constraints[@schumacher2016] (table \@ref(tab:model-archs)). As supported by background knowledge[@marais2010], only CSF White Cell count was modeled via a quadratic effect.

```{r skeleton-model, fig.show='hold', out.width="100%", fig.align="center", fig.cap="Model basic design. Bacillary burden is only included in model 2 +. Test positive probabilities are for demonstration only and do not correspond to the real ones.", fig.id='skeleton-model'}

fig_svg <- cowplot::ggdraw() + 
  cowplot::draw_image(magick::image_read_svg("includes/classicLCA.svg", width=212*5, height=159*5))
plot(fig_svg)
```

By protocol, most patients with a very high chance of or evidently diagnosed with different diseases were not tested with the TBM confirmation assays. We assumed these patients are all negative, because these tests are known to have high specificity[@nhu2013, @heemskerk2018]. Missing predictors were handled case by case basing on their expected missing mechanisms (table \@ref(tab:missing-handling)). In case they were expected to be Missing At Random (MAR), we performed a model-based imputation.

We used a Bayesian approach for estimation. For TBM confirmatory tests sensitivity and specificity we chose Normal prior distributions, on the logit scale, with appropriate means and standard deviations, so that they covered past estimates from earlier studies involving Vietnamese cohorts[@thwaites2004; @nhu2013; @heemskerk2018] (figure \@ref(fig:mv-priors)).<!-- Weakly informative priors for True Positive Rate (TPC = Sensitivity) given the discrepancies between different research.--> We also used *Normal* distribution for the relation of covariates in both prevalance and bacilliary models, but with weakly informative configurations. Posterior distributions were obtained via Hamiltonian Markov Chain Monte Carlo, using the Stan program and its R interface in the RStan[@stan-doc] package. 

All model performances were estimated and compared by (1) expected log point-wise predictive density (elpd) [@vehtari2016], (2) calibration metrics and calibration curves[@rms; @VanCalster2019], and (3) Receiver Operating Characteristic (ROC) curves and corresponding Area Under the Curve (AUC). All metrics were estimated using a pooled dataset held out from 5 repetitions of 20-fold cross validation.<!--Pair-wise residual correlation were plotted to validate the local independence assumption, after correction for local effects [@qu1996; @schumacher2016].--> For demonstration, we visualised class-wise predicted probability density plots depicting how separable predicted values are between two classes. We also used the diagnosis at discharge (if available) as a pseudo-gold standard to visualise the correlation of our model-based prediction and delayed clinical diagnosis. 

```{r mv-priors, fig.cap="Density plots for prior distributions and their adherence to prior knowledge of sensitvity and specifity for TBM confirmation tests, against then-made clinical diagnosis. Note that Thwaites 2004 was descriptive only while ZN and Culture in Nhu 2013 were references hence no Confidence Interval", warning=FALSE,  fig.align='center', out.width='90%', fig.id="mv-priors", fig.height=8, dpi=300 }
sen_tbl <-
  tibble::tibble(
    'Test' = rep(c('ZN', 'Culture', 'Xpert'), 3),
    'Study' = rep(c('Thwaites 2004', 'Nhu 2013', 'Heemskerk 2018'), each=3),
    'est' = c(58/100, 64/100, NA, 78.64/100, 66.54/100, 59.34/100, 34.54/100, 31.84/100, 25.14/100),
    'lower.ci' = c(NA, NA, NA, 71.94/100, 59.14/100, 51.84/100, 29.94/100, 27.34/100, 21.04/100),
    'upper.ci' = c(NA, NA, NA, 84.34/100, 73.34/100, 66.54/100, 39.44/100, 36.74/100, 29.74/100)
  )

spc_tbl <-
  tibble::tibble(
    'Test' = rep(c('ZN', 'Culture', 'Xpert'), 3),
    # Test_id = rep(c(3,1,2), 2),
    'Study' = rep(c('Thwaites 2004','Nhu 2013', 'Heemskerk 2018'), each=3),
    'est' = c(NA, NA, NA, 0, 0, 0.05/100, 0, 0, 0),
    'upper.ci' = c(NA, NA, NA, NA, NA, (100-97.2)/100, (100-97.1)/100, (100-96.9)/100, (100-96.1)/100),
    'lower.ci' = c(NA, NA, NA, NA, NA, 0, 0, 0, 0)
  )

spc_rng = rbind(
  data.frame(
    Test = 'ZN',
    Test_id = 1,
    logit = rlogis(1000000,qlogis(.001),1.1),
    linear = rlogis(1000000,qlogis(.001),1.1) |> plogis()
  ),
  data.frame(
    Test = 'Culture',
    Test_id = 2,
    logit = rlogis(1000000,qlogis(.001),1.1),
    linear = rlogis(1000000,qlogis(.001),1.1) |> plogis()
  ),
  data.frame(
    Test = 'Xpert',
    Test_id = 3,
    logit = rlogis(1000000,qlogis(.005),.7),
    linear = rlogis(1000000,qlogis(.005),.7) |> plogis()
  )
) |>
  filter(linear<.1)
  

sen_rng = rbind(
  data.frame(
    Test = 'ZN',
    Test_id = 1,
    logit = rlogis(500000, 0,.3),
    linear = rlogis(500000, 0,.3) |> plogis()
  ),
  data.frame(
    Test = 'Culture',
    Test_id = 2,
     logit = rlogis(500000, 0,.3),
    linear = rlogis(500000, 0,.3) |> plogis()
  ),
  data.frame(
    Test = 'Xpert',
    Test_id = 3,
    logit = rlogis(500000, 0,.3),
    linear = rlogis(500000, 0,.3) |> plogis()
  )
) 

spc_linear_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=linear), data=spc_rng) +
  geom_point(aes(y= est, color = Study, x = -.2), data=spc_tbl, position=position_dodge(.2), shape=18, size=3) + 
  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci, color = Study, x = -.2), data=spc_tbl, position=position_dodge(.2)) +
  coord_flip(ylim=c(0,.05))+
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  scale_color_discrete(drop=FALSE)+
  theme_minimal() +
  theme(text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

spc_logit_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=logit), data=spc_rng) +
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  coord_flip(ylim=c(-15, 2.5)) +
  theme_minimal() +
  theme(text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

sen_linear_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=linear), data=sen_rng) +
  geom_point(aes(y= est, color = Study, x = -.2), data=sen_tbl, position=position_dodge(.2), shape=18, size=3) + 
  geom_linerange(aes(ymin = lower.ci, ymax = upper.ci, color = Study, x = -.2), data=sen_tbl, position=position_dodge(.2)) +
  coord_flip()+
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  theme_minimal() +
  theme(text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

sen_logit_plt <- ggplot() + 
  ggdist::stat_halfeye(mapping=aes(y=logit), data=sen_rng) +
  facet_grid(Test~.)+
  xlab('') + ylab('') +
  coord_flip() +
  theme_minimal() +
  theme(text = element_text('serif', size = 9), 
        plot.tag = element_text('serif', size = 9),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
  

plt <- (spc_linear_plt + ggtitle('FPR (1-Specificity)') + theme(legend.position = "none") | spc_logit_plt) /
  (sen_linear_plt + ggtitle('TPR (Sensitivity)') + theme(legend.position = "bottom") | sen_logit_plt) 

for (i in 1:2) plt[[i]] <- plt[[i]] + plot_layout(tag_level = 'new')
color_me <- list("#000000", "#E69F00", "#56B4E9", c("#000000", "#E69F00", "#56B4E9", "#009E73"))
withr::with_options(
  list(ggplot2.discrete.colour = color_me),

  plt + plot_annotation(tag_levels = list(c('',''), 'A'), caption='A: Linear scale, B: Logistic Scale \n Black dots, thick lines and thin lines are median, IQR, and 95% inter-percentile range') + plot_layout(guides = 'collect') & theme(text = element_text('serif', size = 9), plot.tag = element_text('serif', size = 9), legend.position = "bottom") 
)
```

### Sensitivity and exploratory analysis

Since latent class analysis models unobserved characteristics, results may be strongly dependent on our assumptions. Therefore, we conducted sensitivity analyses where some assumptions were lifted or changed. We first increased the standard deviation of our prior for specificities of all confirmatory tests so that every value in the range of 90%-100% were accepted. We also changed the prior distributions of the parameters in the prevalence and bacillary burden models from *normal* to a more skeptical one *Student's t* with 4 degrees of freedom; means and scales, however, were kept as-is. Their *elpd*s were compared. Thirdly, as recent studies suggested a sup-optimal specificity of Xpert test on CSF samples [@nhu2013; @chen2020], we considered a Missing-At-Random scenario, where observation chance of confirmation tests depend on the unknown TBM status and locally independent to the value of confirmation tests. Observation status was then included in the model as a separated manifest variables. We visualised the estimates of this model with the best performing one in our main analysis.

Furthermore, to explore hidden effects, we added quadratic terms for all five CSF bio-markers and RGCS to the prevalence model; CSF volume was additionally included to capture its potential impact on test sensitivity. *Laplace* priors were utilised instead of *Normal* for all linear covariates. Posteriors and performance metrics of this model were reported.

### Simplified classification model

We lastly developed a simplified linear model approximating the previously estimated latent probabilities but without laboratory features. To achieve this, we transferred the analytic forms of posteriors outputted by the best performing model, on the logit scale, to a separate linear regression where the number of predictors were reduced and error terms were assumed to follow standard *logistic* distribution.

All data preparation, cleaning, and processing were performed on statistical package R, version 4.1.1 [@rcoreteam]. The model was developed on the probabilistic language Stan via the interface RStan , version 2.27 [@stan]. Plotting was done using package bayesplot [@bayesplot], classifierplots [@classifierplots], and ggvenn [@ggvenn]. Some other packages used include: R6 [@r6] and rms [@rms]. All estimations came from 8000 effective iterations of 4 MCMC chains. Convergence and effectiveness of MCMC chains were evaluated by Brooks-Gelman-Rubin statistic ($\hat{R}$) and Effective Sample size[@stan-doc]. Mathematical formulations and technical adjustments were detailed in the supplementary documents. All code were published on [project's github repo](github.com/TBM-LCA).

# Results

## Clinical characteristics

From 29th August 2017 to 22nd January 2021, there were `r nrow(data_dirty)` patients enrolled in the main study, amongst them `r nrow(data_19EI)` were included in the analysis. `r nrow(data_dirty) - nrow(data_19EI)` were excluded due to contaminated culture growth. Characteristics of analysed population are shown in table \@ref(tab:test-bl-tbl). There were `r sum(data_19EI$csf_smear, na.rm=TRUE)` ZN Smear, `r sum(data_19EI$csf_mgit, na.rm=TRUE)` MGIT Culturing, and `r sum(data_19EI$csf_xpert, na.rm=TRUE)` Xpert samples got positive result (figure \@ref(fig:venn-test)).

```{r venn-test, out.width='50%', fig.align='center', fig.asp=1, fig.cap = 'Venn diagram for ZN Smear, MGIT, and Xpert'}

data_19EI |>
  mutate(across(c(csf_smear, csf_mgit, csf_xpert), as.logical)) |>
  ggplot() +
  ggvenn::geom_venn(aes(A = csf_smear, B = csf_mgit, C = csf_xpert), 
                    fill_color = c('#E5707E', '#E6B566', '#A3DDCB'),
                    stroke_color = c('#E5707E', '#E6B566', '#A3DDCB'),
                    set_names = c('ZN Smear', 'MGIT', 'Xpert'),
                    text_size = 3, set_name_size = 4) +
  theme_void()

```

\newpage

\blandscape

<!---BLOCK_LANDSCAPE_START--->

```{r test-bl-tbl, echo=FALSE, tab.cap="Baseline characteristics", tab.id="test-bl-tbl"}
bl_tbl <- 
  data_dirty |>
  as_tibble() |>
  mutate(csf_neutro = csf_wbc - csf_lympho - csf_eos) |>
  mutate(
    across(c(csf_smear, csf_xpert, csf_mgit), 
           ~ factor(.x, 
                    levels = c(TRUE, FALSE,NA), 
                    labels = c('Positive', 'Negative', 'Missing'),
                    exclude = NULL
           )
    )
  ) |>
  select(age, hiv_stat, diabetes = ISDIABETE, clin_illness_day, clin_symptoms, clin_contact_tb, clin_motor_palsy, clin_nerve_palsy, GCSV, GCSM, GCSE, clin_gcs, xray_pul_tb, xray_miliary_tb, csf_lympho, csf_wbc, csf_eos, csf_rbc, csf_protein, csf_lactate, csf_glucose, bld_glucose = BLDGLU, csf_crypto, csf_smear, csf_xpert, csf_mgit) |>
  tidyr::pivot_longer(
    c(csf_smear, csf_mgit, csf_xpert),
    names_to = 'Test',
    values_to = 'Result'
  ) |>
  my_fn$add_labels(
    age               = 'Age',
    hiv_stat          = 'HIV Positive', 
    diabetes          = 'Diabetes',
    clin_illness_day  = 'Day from onset',
    clin_symptoms     = 'TB-suggested symptoms',
    clin_contact_tb   = 'Past noticeable contact TB within 12 months',
    clin_motor_palsy  = 'Focal neurological deficit',
    clin_nerve_palsy  = 'Cranial nerve palsy',
    GCSV              = 'Glasgow Coma Scale-Verbal',
    GCSM              = 'Glasgow Coma Scale-Motor',
    GCSE              = 'Glasgow Coma Scale-Eyes',
    clin_gcs          = 'Glasgow Coma Score',
    xray_pul_tb       = 'X-Ray Pulmonary TB',
    xray_miliary_tb   = 'X-Ray Miliary TB',
    csf_lympho        = 'CSF Lymphocyte Count',
    csf_wbc           = 'CSF Total White cell Count',
    # csf_neutro        = 'CSF Neutrophil Count',
    csf_eos           = 'CSF Oeosinophil Count',
    csf_rbc           = 'CSF Red blood cell Count',
    csf_protein       = 'CSF Protein',
    csf_lactate       = 'CSF Lactate',
    csf_glucose       = 'CSF Glucose',
    bld_glucose       = 'Corresponding Blood Glucose',
    csf_crypto        = 'Cryptococcal Antigen/Indian Ink'
  ) |>
  # mutate(- csf_neutro) |>
  mutate(
    Test = case_when(
      Test == 'csf_smear' ~ 'ZN Smear',
      Test == 'csf_mgit'  ~ 'MGIT',
      Test == 'csf_xpert' ~ 'Xpert (Ultra)',
    )
    # Result = ifelse(is.na(Result), 'Missing', Result) |> factor()
  ) |>
  tbl_strata(
    strata = Test,
    .tbl_fun = ~ tbl_summary(
      .x, 
      by = Result,
      missing_text = '  - Missing',
      # type = list(GCSV~'continuous', GCSE~'continuous',GCSM~'continuous'),
      statistic = list(
        all_continuous() ~ '{mean} ({p25}, {p75})'),
      digits = list(csf_eos ~ c(0, 0, 0), clin_gcs ~ c(0, 0, 0), 
                    GCSE ~ c(0, 0, 0), GCSV ~ c(0, 0, 0), GCSM ~ c(0, 0, 0))
    )
  ) |>
  modify_footnote(
    update = all_stat_cols() ~ "Mean (1st, 3rd quartiles) for numeric variables; n (%) for categorical variables",
    text_interpret = "html"
  )

bl_tbl |> as_flex_table() |>
  # flextable::set_caption('Baseline characteristics') |>
  flextable::width(width = .88) |>
  flextable::fontsize(size=9, part = 'all') |>
  flextable::theme_zebra()
```

<!---BLOCK_LANDSCAPE_STOP--->

\elandscape

\newpage

_I am in doubt where to put this part below as it is a mixed between method and results_
```{r missing-handling, tab.cap="Rationales and measures to handle missing values", tab.id="missing-handling"}
na = \(x) sum(is.na(x))
data_dirty$csf_neutro <- data_dirty$NEUPER * data_dirty$csf_wbc / 100
data_dirty %$%
  tibble::tribble(
     ~ 'Variable'           , ~ 'N\n missing'     ,  ~ 'Expected Reason of Missingness'                      , ~ 'Mechanism',        ~ 'Handling method' ,
    'ZN Smear'              , na(csf_smear)       , 'Not suspected TBM'                                      , 'MNAR'               , 'Set = 0'          , 
    'MGIT'                  , na(csf_mgit)        , 'Not suspected TBM'                                      , 'MNAR'               , 'Set = 0'          , 
    'Xpert'                 , na(csf_xpert)       , 'Not suspected TBM'                                      , 'MNAR'               , 'Set = 0'          , 
    'HIV Status'            , na(hiv_stat)        , 'Not suspeted HIV'                                     , 'MNAR'           , 'Impute by population prevalence'       ,
    'TB-suggested symptoms' , na(clin_symptoms)   , 'Unmeasured / Unnoticed / Unconscious'                   , 'MAR'           , 'Imputation'       ,
    'Local neuro-deficit'   , na(clin_motor_palsy), 'Unconscious'                                            , 'MAR/MNAR'           , 'Imputation'       ,
    'Glasgow Coma Score'    , na(clin_gcs)        , 'Intubated / Forgot'       , 'MAR'                , 'Imputation'       ,
    'Age'                   , na(age)             , 'Input error'                                            , 'MCAR'              , 'Imputation'       ,
    'Illness days'          , na(clin_illness_day), 'Patients forget / Unconscious'                          , 'MAR'                , 'Imputation'       ,
    'Blood Lymphocyte'      , na(LYMP)            , 'Unmeasured (premature death)'                           , 'MAR'                , 'Imputation'       ,
    'Blood Neutrophil'      , na(NEUTRO)          , 'Unmeasured (premature death)'                           , 'MAR'                , 'Imputation'       ,
    'Blood Glucose'         , na(BLDGLU)          , 'Most likely input error / Unmeasured (premature death)', 'MAR/MCAR'           , 'Imputation'       ,
    'CSF glucose'           , na(csf_glucose)     , 'Unmeasured (premature death)'                           , 'MAR/MCAR'           , 'Imputation'       ,
    'CSF lymphocyte count'  , na(csf_lympho)      , 'Very low or zero / Input error / Unmeasured (premature death)', 'MNAR/MAR'           , 'Manually set/Imputation',
    'CSF neutrophil count'  , na(csf_neutro)      , 'Very low or zero / Input error / Unmeasured (premature death)', 'MNAR/MAR'           , 'Manually set/Imputation',
    'CSF protein'           , na(csf_protein)     , 'Data input error / Test error'       , 'MAR/MCAR'           , 'Imputation'       ,
    'CSF lactate'           , na(csf_lactate)     , 'Data input error / Test error'                              , 'MAR/MCAR'           , 'Imputation'     
    # 'CSF RBC count'         , na(csf_rbc)         , 'Zero cell count'                                        , 'MNAR'               , 'Set = 0'                  
  ) |>
  flextable::flextable() |>
  # flextable::set_caption('Rationale and method of missing values handling') |>
  flextable::width(width = 1.25) |>
  flextable::footnote(i = c(14,15),j = 1,inline=FALSE,
                      value=flextable::as_paragraph(rep('CSF Cell counts = CSF white-cell count x Pct of Cell Type / 100; if very low, then either lymphocytes or neutrophils had values, the other were left missing')),
                      part = 'body') |>
  flextable::footnote(i = c(1),j = 1,inline=FALSE,
                      value=flextable::as_paragraph(rep('GCS Verbal is assumed to be MAR after correction for the other two, and is predicted by a model-based imputation[@Teasdale2014]')),
                      part = 'body') |>
  flextable::merge_v(part='footer') |>
  flextable::theme_zebra() |>
  flextable::bold(bold=FALSE, part='footer') |>
  flextable::italic(italic=TRUE, part='footer')
```

```{r calc_na}
suspected_hiv <- data_dirty |> filter(DISDIA %in% c('DIA1', 'DIA10', 'DIA12'))
n_test_suspected_hiv <- nrow(suspected_hiv) - na(suspected_hiv$hiv_stat)
```

HIV were tested for `r nrow(data_dirty) - na(data_dirty$hiv_stat)` (`r round((nrow(data_dirty) - na(data_dirty$hiv_stat))/nrow(data_dirty)*100, 0)`%) enrolled individuals and `r n_test_suspected_hiv` (`r (n_test_suspected_hiv/nrow(suspected_hiv)*100) |> round(2)`%) amongst those with suspected conditions. `r na(data_dirty$clin_symptoms)` patients did not provide information for at least one in three TB-suggested symptoms. Amongst `r na(data_dirty$clin_gcs)` individuals with incomplete GCS, GCS Vocal was missing for `r na(filter(data_dirty, is.na(clin_gcs))$GCSV)`.  As HIV was only tested for suspected patients who admitted with HIV-related conditions or involved in high-risk activities, we assumed the HIV rate for the untested group to be similar to that of the general population. Missing GCSV due to intubation is a common issue and the practice of using a model-based imputation approach is supported[@Teasdale2014], as all the Glasgow Coma Scale components are usually highly correlated.

## Model estimation

```{r mv-posterior, tab.cap="Posterior estimates for test positive probabilities in each latent class, CrI: Credible interval", tab.id="mv-posterior"}

est = \(name, tab = z_summary, digits=2, transformation = plogis, ci.sep = ', ', post.fn = I) {
  m <- c(tab[name, 'mean'], tab[name, '50%'], tab[name, '2.5%'], tab[name, '97.5%']) |> transformation() |> formatC(digits=2, format='f') |> post.fn()
  c(m[1], m[2], paste(min(m[3:4]), max(m[3:4]), sep=ci.sep))
}

spc.est = purrr::partial(est,
                         transformation=\(x) 100*(1-plogis(x)), ci.sep='-',
                         post.fn = \(x) paste0(x, '%'))
sen.est = purrr::partial(est, transformation=\(x) 100*plogis(x), ci.sep='-',
                         post.fn = \(x) paste0(x, '%'))

sen = \(name) {
  name = paste0(name, '[2]')
  do.call(sprintf, as.list(c('%s (%s)', sen.est(name)[-2])))
}

spc = \(name) {
  name = paste0(name, '[1]')
  do.call(sprintf, as.list(c('%s (%s)', spc.est(name)[-2])))
}


pr <- matrix(c(
  c('', rep(c('False positive rate (1-Specificity)'),3), rep(c('True positive rate (Sensitivity)'),3)),
  c('Test', rep(c('Mean', 'Median', '95% CrI'),2)),
  c('Smear', est('z_Smear[1]'), est('z_Smear[2]')),
  c('Mgit', est('z_Mgit[1]'), est('z_Mgit[2]')),
  c('Xpert', est('z_Xpert[1]'), est('z_Xpert[2]'))
), byrow=T, nrow=5)

huxtable::as_hux(pr) |>
  huxtable::as_flextable() |>
  flextable::merge_h(i=1, part='body') |>
  flextable::width(width = .85) |>
  flextable::align(i=1, align='center') |>
  flextable::bold(i=1:2) |>
  flextable::theme_zebra()
```

Posterior estimates for diagnosis positive rates of ZN Smear, MGIT, and Xpert against the latent TBM status are reported in table \@ref(tab:mv-posterior). All confirmatory assays have nearly perfect specificity, with Smear being `r spc('z_Smear')`, MGIT `r spc('z_Mgit')`, and Xpert  `r spc('z_Xpert')`. Ziehl-Neelsen, similar to previous paper [@thwaites2004; @nhu2013; @heemskerk2018], was the most sensitive test with `r sen('z_Smear')`. Mycobacterial culturing showed suboptimal sensitivity at `r sen('z_Mgit')`. Different from a recent study [@donovan2020], Xpert and Xpert Ultra were estimatedly the least sensitive indicators for TBM diagnosis, with a test positive rate only `r spc.est('z_Xpert[2]')[1]` for TBM postive class, however the credible interval was wide (`r spc.est('z_Xpert[2]')[3]`).

Estimated coefficients for risk factors for TB are shown in figure \@ref(fig:coef-est). Continuous features are scaled by 2 times of standard deviations and binary features were kept as-is. Patients with HIV, Miliary TB, and past TBM contacts were in the higher risk group for TBM infection, although 95% credible interval of the last cut 0 due to its scarcity in our population. The three TB systemic symptoms were, however, on average provided minimal extra information. So does Reversed Glasgow Coma Score. Long duration since first onset to admission increases the chance of TBM in our population, in which log odd of TBM increases by `r a_plot$data$m[11] |> round(2)` when sickness period doubles.

Of the laboratory variables, CSF glucose, similar to the uniform case definition[@marais2010], decreased the risk TBM, with protein on the opposite side. They show a similar relation with the bacillary burden estimates in the TBM positive group, with the exception of lymphocyte count. Although higher lymphocyte count in CSF means a higher chance of TBM, it also reduces the expected burden of the disease, presumably reduces the chance of detection of bacteria in the confirmation tests. 

```{r coef-est, out.width='100%', fig.align='center', fig.asp=1, fig.cap = 'Coefficient posterior estimations for TBM risk factors and bacillary burden predictors. Points, thick lines, and thin lines are posterior means, 50\\% and 90\\% credible intervals'}
(a_plot + ggtitle('TBM Risk factor')) /
  (b_plot + ggtitle('Bacillary burden predictors')) + 
  theme(text = element_text('serif', size = 9), plot.tag = element_text('serif', size = 9), axis.text.y = ggtext::element_markdown(family=NULL, face='bold'), legend.position = "bottom") 
```

## Model validation 

```{r best-metrics-prep, message=FALSE, warning=FALSE, include=FALSE}
m3 <- readRDS(file.path(data_dir, '..', 'export', 'metrics', 'm3s.RDS'))
with(my_fn, {
  my_roc_plot <- 
  function(obs, pred, pred_rep = NULL, resamps = 2000, force_bootstrap = NULL){
    require(ggplot2)
    require(data.table)
    
    plt <- ggplot()
    for (.pred_rep in pred_rep)
      plt <- ._add_roc_plot(plt, obs, .pred_rep, resamps, force_bootstrap, .rep = TRUE)
    plt <- ._add_roc_plot(plt, obs, pred, resamps, force_bootstrap, .rep = FALSE, .has_rep = length(pred_rep))
    plt # + coord_cartesian(xlim=c(0, 100, ylim=c(0,100)))
  }
._add_roc_plot <- 
  function (plt, obs, pred, resamps = 2000, force_bootstrap = NULL, .rep = FALSE, .has_rep = FALSE) 
  {
    # browser()
    maincolor <- "#CD113B"
    subcolor1 <- "#111111"
    subcolor2 <- "#999999"
    n <- length(obs)
    obs.bin <- obs == 1
    nbins <- min(50, n)
    npositives <- sum(obs.bin)
    nnegatives <- n - npositives
    negative_steps <- floor(nnegatives/50)
    negative_steps <- floor(nnegatives/nbins)
    auc <- classifierplots:::calculate_auc(obs, pred)
    writeLines(paste("AUC:", auc))
    big_data_cutoff <- 50000
    if (!is.null(force_bootstrap)) {
      bootstrap <- force_bootstrap
    }
    else {
      bootstrap <- n <= big_data_cutoff
    }
    pos_pred_probs <- -pred[obs.bin]
    neg_pred_probs <- -pred[!obs.bin]
    if (bootstrap) {
      writeLines("Bootstrapping ROC curves")
      pos_pred_boots <- pos_pred_probs[c(caret::createResample(pos_pred_probs, 
                                                               times = resamps, list = F))]
      neg_pred_boots <- neg_pred_probs[c(caret::createResample(neg_pred_probs, 
                                                               times = resamps, list = F))]
      roc_tbl <- data.table(preds = c(pos_pred_boots, neg_pred_boots), 
                            y = c(rep(T, length(pos_pred_boots)), rep(F, length(neg_pred_boots))), 
                            resample = c(rep(1:resamps, each = length(pos_pred_probs)), 
                                         rep(1:resamps, each = length(neg_pred_probs))))
      setkey(roc_tbl, "resample", "preds")
      roc_tbl[, `:=`(tp, cumsum(y)), by = resample]
      roc_tbl[, `:=`(fp, cumsum(!y)), by = resample]
      roc_tbl[, `:=`(fpr_step, ((fp%%negative_steps) == 0)), 
              by = resample]
      substeps_tbl <- roc_tbl[fpr_step == T, ]
      subind <- substeps_tbl[, .I[.N], by = c("resample", 
                                              "fp")]
      roc_tbl_sub <- substeps_tbl[subind$V1]
      roc_tbl_sub_stats <- roc_tbl_sub[, as.list(quantile(tp, 
                                                          c(0.025, 0.5, 0.975))), keyby = fp]
      writeLines("Eval AUC")
      roc_tbl[, `:=`(rank, mean(.I)), by = c("resample", "preds")]
      r1 <- roc_tbl[y == T, sum(rank) - .N * n * (resample - 
                                                    1), keyby = "resample"]$V1
      u1 <- r1 - (npositives * (npositives + 1))/2
      aucs <- 1 - u1/(npositives * nnegatives)
      auc_bounds <- 100 * quantile(aucs, c(0.025, 0.5, 0.975))
      digits_use <- 3
      if (format(auc_bounds[1], digits = digits_use) == format(auc_bounds[3], 
                                                               digits = digits_use)) {
        digits_use <- 5
      }
    }
    else {
      roc_tbl <- data.table(preds = c(pos_pred_probs, neg_pred_probs), 
                            y = c(rep(T, length(pos_pred_probs)), rep(F, length(neg_pred_probs))))
      setkey(roc_tbl, "preds")
      roc_tbl[, `:=`(tp, cumsum(y))]
      roc_tbl[, `:=`(fp, cumsum(!y))]
      roc_tbl[, `:=`(fpr_step, ((fp%%negative_steps) == 0))]
      substeps_tbl <- roc_tbl[fpr_step == T, ]
      subind <- substeps_tbl[, .I[.N], by = c("fp")]
      roc_tbl_sub_stats <- substeps_tbl[subind$V1]
      roc_tbl_sub_stats[, `:=`(`50%`, tp)]
    }
    writeLines("Producing ROC plot")
    
    # plt <- ggplot()
    plt <- plt + geom_line(data=roc_tbl_sub_stats, 
                     mapping=aes(x = 100 * fp/nnegatives, 
                                 y = 100 * `50%`/npositives),
                     color = if (!.rep) classifierplots:::green_str else subcolor2, 
                     size = if (!.rep) 1 else .5,
                     alpha =  if (!.rep) 1 else .5) + 
      geom_abline(slope = 1, intercept = 0, linetype = "dotted") 
    
    if (!.rep) 
      plt <- plt + 
      annotate("text", x = 62.5, y = 22.5, label = paste0("AUC ", format(auc, digits = 3), "%"),
               parse = F, size = 4, colour = classifierplots:::fontgrey_str) + 
      scale_x_continuous(name = "False Positive Rate (%)    (1-Specificity)", 
                         limits = c(0, 100), expand = c(0.05, 0.05)) + 
      scale_y_continuous(name = "True Positive Rate (%)    (Sensitivity)", 
                         limits = c(0, 100), expand = c(0.05, 0.05))
    
    if (bootstrap) {
      plt <- plt + geom_ribbon(mapping = aes(x = 100 * fp/nnegatives, 
                                             ymin = 100 * `2.5%`/npositives, 
                                             ymax = 100 * `97.5%`/npositives), 
                               data=roc_tbl_sub_stats, 
                               # fill = if (!.rep) classifierplots:::green_str else subcolor2, 
                               fill = classifierplots:::green_str, 
                               alpha = if (.has_rep) .1 else .2) 
      if (!.rep)
        plt <- plt +
          annotate("text", x = 62.5, y = 15, 
                   label = paste0("95% CI: ", 
                                  format(auc_bounds[1], digits = digits_use),
                                  "% - ", format(auc_bounds[3], digits = digits_use), "%"), 
                   parse = F, size = 2.8, colour = classifierplots:::fontgrey_str)
    }
    return(plt)
  }
})

plot_theme <- theme(axis.title = element_blank(), text=element_text(size=7))

rocs <- 
  (my_fn$my_roc_plot(obs = data_19EI$csf_smear, pred = m3$p$p_Smear$mean) + ggtitle('Smear') + theme_bw() + plot_theme)+
  (my_fn$my_roc_plot(obs = data_19EI$csf_mgit, pred = m3$p$p_Mgit$mean) + ggtitle('Mgit') + theme_bw() + plot_theme)+ 
  (my_fn$my_roc_plot(obs = data_19EI$csf_xpert, pred = m3$p$p_Xpert$mean) + ggtitle('Xpert') + theme_bw() + plot_theme) 

rocs <-  
  patchworkGrob(rocs) |>
  gridExtra::grid.arrange(
    left = "True Positive Rate (%)    (Sensitivity)", 
    bottom = "False Positive Rate (%)    (1-Specificity)")


calib <- td.misc::binary_calibration(pred=m3$p$p_Smear$mean, obs=data_19EI$csf_smear, span=1) + plot_theme +
     td.misc::binary_calibration(pred=m3$p$p_Mgit$mean, obs=data_19EI$csf_mgit, span=1) + plot_theme + 
     td.misc::binary_calibration(pred=m3$p$p_Xpert$mean, obs=data_19EI$csf_xpert, span=1) + plot_theme

calib <- patchworkGrob(calib) |>
  gridExtra::grid.arrange(
    left = "Observed", 
    bottom = "Predicted")

```

```{r best-metrics, fig.align='center', fig.cap='ROC curves and calibration plots for selected model', fig.dim=c(8,6), message=FALSE, warning=FALSE, out.width='100%'}
w = wrap_plots(rocs, calib, ncol=1)
plot(w)
```

All MCMC chains converged with decent $\hat{R}$ and effective sample size. Selected model with highest *elpd* = `r (m3$elpd$estimates[,'Estimate']) |> round(2)`. It provides good discrimination between TBM and non-TBM status, with 5x20-fold-CV *AUC* = `r classifierplots:::calculate_auc(test.y = data_19EI$csf_smear, pred.prob = m3$p$p_Smear$mean) |> round(0)`% for ZN Smear, `r classifierplots:::calculate_auc(test.y = data_19EI$csf_mgit, pred.prob = m3$p$p_Mgit$mean) |> round(0)`%, and  `r classifierplots:::calculate_auc(test.y = data_19EI$csf_xpert, pred.prob = m3$p$p_Xpert$mean) |> round(0)`% for Xpert. Average predicted probabilities were comparable to observed positivity rates, whereas calibration intercepts were estimated near 0 and calibration slope approximately 1 for all three manifest variables. Calibration curves against non-parametric loess fits (figure \@ref(fig:best-metrics)) depict highly precise moderate calibration [@VanCalster2019] for Ziehl-Neelsen smearing, and a slight drop at the upper end for MGIT culture and Xpert; however, as shown in the corresponding histograms, there were only few participants with predicted high chance of positive test result, hence the lower certainty. A full summary of model metrics and residual correlation plots are shown in the supplementary document.

We also used the diagnosis at discharge time as a pseudo-gold standard to visualise the calibration and AUC for the predicted TBM prevalence (figure \@ref(fig:theta-metrics)). The AUC for TBM prediction are `r classifierplots:::calculate_auc(test.y = !data_19EI$other_dis_dx, pred.prob = m3$p$theta$mean) |> round(2)`% and calibration plots show some over-estimation at the centre. 

```{r theta-metrics-prep, include=FALSE}
theta_rocs <- 
  my_fn$my_roc_plot(obs = !data_19EI$other_dis_dx, pred = m3$p$theta$mean) + ggtitle('Discharge Diagnosis') + theme_bw()
theta_calib <- td.misc::binary_calibration(pred=m3$p$theta$mean, obs=!data_19EI$other_dis_dx, span=1) + theme_bw()
```

```{r theta-metrics, fig.align='center', fig.cap='ROC curves and calibration plots for selected model againts discharge diagnosis', fig.dim=c(6,3), message=FALSE, warning=FALSE, out.width='100%'}
theta_rocs+theta_calib
```

## Sensitivity analysis

## Simplifed model

Estimated scores for clinical signs and symptoms are shown in \@ref(fig:simplified-model). HIV+ and illness day still support a TBM diagnosis, while Reversed GCS predict against it. Local nerve palsy and cranial nerve palsy, without the existence of laboratorial tests, both showed themeselve as positive risk factor for TBM.

_I don't know what to say here. There shall be a calibration plot, but for estimations, I am out of words_
```{r simplified-model, fig.align='center', fig.cap='Estimation of simplified TBM risk factors', message=FALSE, warning=FALSE, out.width='70%'}
# tmp_svg <- cowplot::ggdraw() + 
#   cowplot::draw_image(magick::image_read_svg("includes/a_plog_s.svg", width=212*5, height=159*5))
# plot(tmp_svg)
a_plot_s <- readRDS(file.path(data_dir, '..', 'export', 'a_plot_s.RDS'))
plot(a_plot_s)
```

# Discussions

We implemented the Bayesian Latent Class Analysis for a large population consisted of `r nrow(data_19EI)` patients with suspected neurological infection. Using different level of capacity, we managed to capture many non-linear correlations and hidden factors, while still maintain its full interpretability. Through this, we successfully estimated the positive rates for corresponding confirmation procedures. Ziehl-Neelsen Smear, despite its simplicity and availability, continues to prove its superiority over other two with `r sen('z_Smear')` of sensitivity[@nhu2013; @donovan2020]. GeneXpert, as being the most developed and costly, performed surprisingly poorly on CSF samples (`r sen('z_Xpert')`). MGIT culturing provides intermediate results (`r sen('z_Mgit')`) and is a good combination to Smear, due to its simplicity. However, one huge downside of culturing is its time gap, which may unnecessarily delay to diagnosis and hence treatment. Note that no test amongst three provides highly reliable sensitivity to be used alone; a novel true gold standard is as a results still urgently need. On the flip side, all three assays perform well in detecting non-TBM, with mostly no false positive; these reflect well the biological mechanisms of the tests.

Compared to the most recent study[@donovan2020], where the authors used one subset of our data with 305 patients, estimated sensitivities were lower for all three assays. In that analysis, ZN Smear was estimatedly 71.3% sensitive, while MGIT and Xpert was 47.9% and 39.6% respectively. Their confidence intervals and our credible intervals still overlapped, however. There are explanation for this discrepancy. First is the difference in denominator. In the earlier one, sensitivity were calculated against the current standard uniform case definition which is deliberately favoured the test results and left out a whole group with score lower than 6, whereas ours were calculated against the actual TBM status. This might also suggest a misdiagnosis of TBM when using the current approach, particularly for those with negative test results <may be we can calculate probs TBM in case all test negative to demonstrate this>; the underperformance was again visualised in the calibration plot against discharge diagnosis (figure \@ref(fig:theta-metrics)), with a small dip on the fitted line at the around $x = 0.5$.

<!--One important output of the model is the actual TBM risk. Despite being design for research, due to the categorical nature, current TBM studies usually suffer difficulty in which group of patients should be considered as TBM. By providing the risk probability, our model can benefit both. A study of only definite TBM might favour severe patients while a lower group might have more false positive mixed with them. Choosing a cut-off usually comes with large trade-off, as a large group of patient would be excluded or included. By providing a probability, our model can benefit both clinicians and researchers with more clear insight, and more flexible choices of cut-off. In prognosis research, this probability, together with the ordinal quanitification of bacillary burden, can be incorporated as correction parameters for patients' responses to TBM treatment regimen, which is usually quite specific. 
=======
Through the implication of LCA, our model succesfully estimated the positive rates for corresponding confirmation procedures. We founds out that GeneXpert, in combination with Xpert Ultra, was not superior to other confirmatory tests, at least for TBM diagnosis, contrary to its popularity and benefit for pulmonary TB <citation>. Compared to estimations the most recent one [@donovan2020], where the authors used one subset of data with 305 patients, the estimated sensitivity were lower for all three assays, with ZN Smear stood at 67% (compared with 71.3%), MGIT culture 31% (47.9%), and Xpert was 13% (39.6%). We would argue that the latter were against standard uniform definition which is in favor of the confirmatory tests themselves, whereas ours were calculated against the actual TBM status, regardless of the test results. This might also be a suggestion of a small misdiagnosis of TBM when using the current approach, particularly for those with negative test results <may be we can calculate prob TBM in case all test negative to demonstrate this>. This underperfomance was again shown in the calibration plot against discharge diagnosis, with a small dip of observed risk at the around 50%. In fact, we all agree that none amongst the three confirmation indicators are reliable to be used alone as gold standard, and a true gold standard is urgently needed. They, however, all performs well in TBM negative class, with mostly no false positive. These estimations reflect well the biological mechanisms of the tests.
>>>>>>> Stashed changes-->

Another finding of our study is the statistical-based estimation of individual TBM probability and contribution of current known diagnostic criteria. From our data, we witnessed that some used predictors like TB-suggested symptoms and cranial nerve palsy have minimal impact on the risk of TBM. This is contrary to previous consensual definition[@marais2010] where the former had a score of 2 and the latter of 1. On the other hand, HIV, albeit not mentioned in the original score, turns out to be very important, with an estimated coefficient of `r a_plot$data$m[1] |> round(2)`. The case of HIV has been well-known, to remedy this, usually, doctors just considered two sub-population differently, added a implicit bonus point for HIV positive patients.  TB-suggested symptoms, in spite of its name, are very non-specific and are prone to noise, while cranial nerve palsy might also appears in several neurological diseases. Laboratorial parameters in general follow the same trend as background knowledge.

A novel quantification of our model is the bacillary burden at baseline. Though it does not have a unit, the number can be a rough estimator for patient severity at baseline, given TBM. HIV was indeed a positive risk factor for severity, so were CSF white cell and lactate. Lymphocyte count in CSF, consistent to a recent study[@Thao2018], intriguingly reduces the bacilliary burden and improves long-term prognosis. In general, the higher Lymphocyte count in CSF, the more likely that the patients have a positive, but mild, TBM.

Basing on our posterior estimations, we proposed a mathematical formula to calculate TBM probability <cross-ref>. A Shiny app was built as a convenient tool for research purpose, which will cover the level of uncertainty. In clinical settings, we also provide a simplified scoring system, based on our simplification model. This system only needs demographic and clinical inputs, and are usually easier to diagnose, as early as admission time. Compared to the cartegorical risk level, an actual probability can provide clinicians with better insight, more flexibility to choosing who are to be included in a study, and vice versa. In prognosis research, the probability, in combination with the predicted bacillary burden, can be incorporated as correction parameters for patients' responses to TBM treatment regimen, which is usually quite specific.

```{r pseudo-fit}

```


```{r corrected-score, tab.cap="Corrected TBM definition, as compared the uniform case definition", tab.id="corrected-score"}



```

All models we considered were carefully and rigorously validated. None of them showed inconstistent results. Model 3, 4, and 5 showed relatively small difference in performance, which also suggested the robustness of our designed. The selected model 3 shows great discrimation and calibration for all three confirmatory tests. The calibration against the pseudo-gold standard diagnosis at discharge showed mild level of overestimation. However, as discussed above, this diagnosis was uncertain and error-proned, which motivated us to use the latent class analysis approach. Discrimation on this was still great with nearly 95% of AUC. On the flip side, this might leave an open question to further research, as there might very well be some hidden factors that we failed to capture. 

This study have some limitations. One major challenges of our model is the amount of missing data, especially in HIV status. We had to make several asssumptions, and despite some sensitivity analyses were made to fill the gap, this can be a huge factors that bias the results. Another disadvantage is the population from which our sample originated. Our study cohort was patients with *suspected* neurological infection, which implies some level of arbitrary, as different hospital in different areas do not necessarily share the same judgement and experience. In that context, a further, multi-site, multi-national study is in needed. And even if that is omittable, our sample can still not be respresentative for the whole population, and our probability is potentialy overestimated. Neither in clinical pratice nor research field would that be an issue, as usually they are the cohort of interest. However, when doing populational surveilance, this must be taken into account; as we would advise against extrapolation under such a circumstance. Rather, it is better to perform a Bayesian correction basing on the prevalence  of neurological infection in the society. The third issue can come from the design of our models that is still heavily dependent on current knowledge. Although we tried to as many as possible factors to correct for hidden effect, accidentally fusing some amount of noise might impact on the overall estimations. Additionally, in some niche cases, the predicted credible intervals for TBM risk can be very wide. Although, as suggested by the results, the mean estimation alone can be used in practice with minimal trade-offs, in research where the uncertainty should be incorporated and captured properly, this can render the model less useful. 

# Conclusion

Our Bayesian LCA model yield good and well-calibrated results. A novel diagnostic gold standard is still urgently needed as no test perform superiorly reliable. Until then, our scoring system can be an objective diagnostic tool and baseline severity estimator in both clinical practice and research, for patients with suspected neurological infection. 

# References

::: {#refs}
:::
